# Foundations of Probability and Statistics

This chapter builds the probabilistic and statistical foundations that underpin every later section of POT.

## Learning Objectives

- Understand probability axioms, conditional probability, and Bayes' rule.
- Distinguish between discrete and continuous random variables and their distributions.
- Master expectation, variance, covariance, and transformations of random variables.
- Develop intuition for sampling distributions, estimation, and hypothesis testing.

## Outline

1. **Probability Basics**: sets, events, counting rules, conditional probability.
2. **Random Variables**: discrete and continuous distributions, moments, MGFs/characteristic functions.
3. **Multivariate Distributions**: joint, marginal, conditional distributions; covariance and correlation structures.
4. **Limit Theorems**: law of large numbers, central limit theorem, convergence concepts.
5. **Estimation**: point estimators, properties (bias, consistency, efficiency), method of moments, maximum likelihood.
6. **Inference**: confidence intervals, hypothesis testing, p-values, power analysis.

## Resources

- Worked examples using simulated data in notebooks (`foundations_probability.ipynb`, etc.).
- Quick reference sheets summarizing common distributions and test statistics.
- Links to classic texts (Casella & Berger, Wasserman) in the `references/` directory.

## Exercises

- Derive expectations and variances for specified distributions.
- Simulate sampling distributions and compare empirical results to theoretical predictions.
- Design hypothesis tests for real or synthetic datasets and interpret results.
